{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6b32f-3e80-4d3e-8d8c-ccb0e6da70fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactored Code with Improved Structure and Cleaned-Up Components\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, matthews_corrcoef, average_precision_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import Parallel, delayed\n",
    "from imblearn.over_sampling import SMOTE, SMOTEN\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Constants (Replace with configuration-based paths)\n",
    "DATA_PATH = \"path/to/data_directory\"\n",
    "OUTPUT_PATH = \"path/to/output_directory\"\n",
    "\n",
    "# Function for processing city-year data\n",
    "def process_city_year(city, start_year, end_year):\n",
    "    \"\"\"\n",
    "    Processes data for a specific city and year range, preparing training and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - city (str): The city name.\n",
    "    - start_year (int): The starting year.\n",
    "    - end_year (int): The ending year.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Processed data including city, years, training and test data, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Construct file paths\n",
    "        new_format_start = f\"{city.lower()}_cd_{start_year}_tech\"\n",
    "        new_format_end = f\"{city.lower()}_cd_{end_year}_tech\"\n",
    "        \n",
    "        file_path_start = os.path.join(DATA_PATH, f\"{new_format_start}.csv\")\n",
    "        file_path_end = os.path.join(DATA_PATH, f\"{new_format_end}.csv\")\n",
    "\n",
    "        # Read data files\n",
    "        df_start = pd.read_csv(file_path_start)\n",
    "        df_end = pd.read_csv(file_path_end)\n",
    "\n",
    "        # Process column names and binary encoding\n",
    "        new_column_names = [f'IPC{i+1}' for i in range(len(df_start.columns))]\n",
    "        df_start.columns, df_end.columns = new_column_names, new_column_names\n",
    "\n",
    "        df_train = df_start.applymap(lambda x: 1 if x > 0 else 0)\n",
    "        df_test = df_end.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "        # Split data\n",
    "        X, Y = df_train.T.values[:, 1:50], df_test.T.values[:, 0]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "\n",
    "        # Apply SMOTE\n",
    "        smote = SMOTEN(random_state=7)\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # Label encoding\n",
    "        y_train_smote = le.fit_transform(y_train_smote)\n",
    "        y_test = le.transform(y_test)\n",
    "\n",
    "        return city, start_year, end_year, X_train_smote, X_test, y_train_smote, y_test\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for {city} in years {start_year} or {end_year}. Skipping...\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for {city} in years {start_year} and {end_year}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function for hyperparameter tuning\n",
    "def tune_hyperparameters(data, param_grid):\n",
    "    \"\"\"\n",
    "    Tunes hyperparameters for a RandomForestClassifier using GridSearchCV.\n",
    "\n",
    "    Parameters:\n",
    "    - data (tuple): Processed data including city, years, and train/test splits.\n",
    "    - param_grid (dict): Hyperparameter grid for RandomForestClassifier.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Model performance metrics and best parameters.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        city, start_year, end_year, X_train_smote, X_test, y_train_smote, y_test = data\n",
    "\n",
    "        model = RandomForestClassifier(random_state=7)\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1_weighted', n_jobs=4)\n",
    "        grid_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "        best_param = grid_search.best_params_\n",
    "        \n",
    "        # Train with best parameters\n",
    "        model = RandomForestClassifier(**best_param, random_state=7)\n",
    "        model.fit(X_train_smote, y_train_smote)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        matthews = matthews_corrcoef(y_test, y_pred)\n",
    "        pr_auc = average_precision_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "        # Result dictionary\n",
    "        result = {\n",
    "            'city': city, 'start_year': start_year, 'end_year': end_year,\n",
    "            'accuracy': accuracy, 'precision': precision, 'f1_score': f1,\n",
    "            'matthews_corrcoef': matthews, 'classification_error': 1 - accuracy,\n",
    "            'pr_auc': pr_auc, **best_param\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during hyperparameter tuning for {city} in years {start_year} and {end_year}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main processing routine\n",
    "def main(cities, years, param_grid):\n",
    "    \"\"\"\n",
    "    Main routine for processing city-year data, hyperparameter tuning, and saving results.\n",
    "\n",
    "    Parameters:\n",
    "    - cities (list): List of cities.\n",
    "    - years (range): Range of years to consider.\n",
    "    - param_grid (dict): Hyperparameter grid for RandomForestClassifier.\n",
    "    \"\"\"\n",
    "    # Process data in parallel\n",
    "    preprocessed_data = Parallel(n_jobs=8, verbose=10)(\n",
    "        delayed(process_city_year)(city, start_year, start_year + 5) for start_year in years for city in cities\n",
    "    )\n",
    "    preprocessed_data = [data for data in preprocessed_data if data is not None]\n",
    "\n",
    "    # Hyperparameter tuning in parallel\n",
    "    results = Parallel(n_jobs=8, verbose=10)(delayed(tune_hyperparameters)(data, param_grid) for data in preprocessed_data)\n",
    "    results = [result for result in results if result is not None]\n",
    "    \n",
    "    # Save results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(os.path.join(OUTPUT_PATH, 'results.csv'), index=False)\n",
    "\n",
    "    # Aggregate and save average results\n",
    "    avg_results_df = results_df.groupby('city').agg({\n",
    "        'n_estimators': 'mean', 'max_depth': 'mean',\n",
    "        'min_samples_split': 'mean', 'min_samples_leaf': 'mean',\n",
    "        'bootstrap': lambda x: x.mode()[0]  # Mode as the most frequent value\n",
    "    }).reset_index()\n",
    "    \n",
    "    avg_results_df.to_csv(os.path.join(OUTPUT_PATH, 'avg_results.csv'), index=False)\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Uncomment to run with actual data:\n",
    "# main(cities=['City1', 'City2'], years=range(2000, 2009), param_grid=param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6bc19-0d20-4fb0-8e0f-73e1a5fd3ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c992c9-3e79-4936-a018-c02078a34532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c05eeb-7c12-4fe2-bff4-6de0d2dced25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d2e8a-3925-4a7c-b363-c57dec2b0d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e24bdd-4c29-4243-bf7c-1f6cdf37b12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9dcb31-0ac6-4d19-a756-a33f514afa11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda2605-aa7d-4e5a-ae53-b249bcf656c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141202ba-3a05-439e-ae4c-2e5424662b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778ae01c-5564-4868-a60e-b8d640351163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb708fa5-519d-4803-9cf0-61c21058a891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de472e71-5363-4c2b-b4bb-f0828473783b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
